{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ceb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data.load_data import *\n",
    "from processing.utils import *\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "seed = 2022\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "checkpoint_path = Path('resource/gen2/v1').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6586fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a midi file as an array of events\n",
    "def read_midi(midi_path):\n",
    "    note_items, tempo_items = read_items(midi_path)\n",
    "    note_items = quantize_items(note_items)\n",
    "    max_time = note_items[-1].end\n",
    "    chord_items = extract_chords(note_items)\n",
    "    items = chord_items + tempo_items + note_items\n",
    "    groups = group_items(items, max_time)\n",
    "    events = item2event(groups)\n",
    "    return np.array(events, dtype=object)\n",
    "\n",
    "# read in a series of midi files as a list of sequence of events\n",
    "def transform_midi(midi_paths):\n",
    "    # extract events\n",
    "    events = []\n",
    "    for path in midi_paths:\n",
    "        try:\n",
    "          midi = read_midi(path)\n",
    "          events.append(midi)\n",
    "        except:\n",
    "          print(f\"Failed: {path}\")\n",
    "    return np.asarray(events, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b175d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRUCTURE BASED DATA\n",
    "# Group events into a series of event structures:\n",
    "# Structure Component 1: Bar\n",
    "# Structure Component 2: Position, Note Velocity, Note On, Note Duration\n",
    "# Strucutre Component 3: Position, Chord\n",
    "# Structure Component 4: Position, Tempo Class, Tempo Value\n",
    "def build_structures(midi_paths):\n",
    "    dataset = transform_midi(midi_paths=midi_paths)\n",
    "    event_structs = []\n",
    "\n",
    "    for e in dataset:\n",
    "        event_set = []\n",
    "        event_struct = []\n",
    "\n",
    "        for i in range(len(e)-3):\n",
    "            if e[i].name == 'Bar' and i > 0:\n",
    "                bar = Event(e[i].name, None, e[i].value, None)\n",
    "                #event_struct.append(tuple([e[1]]))\n",
    "                #event_set.append(e[i])\n",
    "                event_set.append(bar)\n",
    "                event_struct.append(tuple(event_set))\n",
    "                event_set = []\n",
    "            elif e[i].name == 'Position' and \\\n",
    "                e[i+1].name == 'Note Velocity' and \\\n",
    "                e[i+2].name == 'Note On' and \\\n",
    "                e[i+3].name == 'Note Duration':\n",
    "                position = Event(e[i].name, None, e[i].value, None)\n",
    "                velocity = Event(e[i+1].name, None, e[i+1].value, None)\n",
    "                pitch = Event(e[i+2].name, None, e[i+2].value, None)\n",
    "                duration = Event(e[i+3].name, None, e[i+3].value, None)\n",
    "                #event_struct.append(tuple([e[i], e[i+1], e[i+2], e[i+3]]))\n",
    "                #event_set.extend([e[i], e[i+1], e[i+2], e[i+3]])\n",
    "                event_set.extend([position, velocity, pitch, duration])\n",
    "            elif e[i].name == 'Position' and e[i+1].name == 'Chord':\n",
    "                position = Event(e[i].name, None, e[i].value, None)\n",
    "                chord = Event(e[i+1].name, None, e[i+1].value, None)\n",
    "                #event_struct.append(tuple([e[i], e[i+1]]))\n",
    "                #event_set.extend([e[i], e[i+1]])\n",
    "                event_set.extend([position, chord])\n",
    "            elif e[i].name == 'Position' and \\\n",
    "                e[i+1].name == 'Tempo Class' and \\\n",
    "                e[i+2].name == 'Tempo Value':\n",
    "                position = Event(e[i].name, None, e[i].value, None)\n",
    "                t_class = Event(e[i+1].name, None, e[i+1].value, None)\n",
    "                t_value = Event(e[i+2].name, None, e[i+2].value, None)\n",
    "                #event_struct.append(tuple([e[i], e[i+1], e[i+2]]))\n",
    "                #event_set.extend([e[i], e[i+1], e[i+2]])\n",
    "                event_set.extend([position, t_class, t_value])\n",
    "            \n",
    "        if event_set:\n",
    "            event_struct.append(tuple(event_set))\n",
    "            event_set = []\n",
    "\n",
    "        event_structs.append(np.asarray(event_struct, dtype=object))\n",
    "\n",
    "    return np.asarray(event_structs, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2091950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lookups(midi_paths, training_set_path, dictionary_path):\n",
    "    event_structs = build_structures(midi_paths=midi_paths)\n",
    "\n",
    "    with open(training_set_path, 'wb') as handle:\n",
    "        pickle.dump(event_structs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Encode all event structures as a indices and build a lookup table\n",
    "    all_event_structs = np.asarray(np.concatenate(event_structs), dtype=object).flat\n",
    "    print(f\"All Event Structures: {len(all_event_structs)}\")\n",
    "\n",
    "    _, indices = np.unique([s for s in all_event_structs], return_index=True)\n",
    "    unique_event_structs = np.asanyarray([all_event_structs[i] for i in indices], dtype=object)\n",
    "    print(f\"Unique Event Structures: {len(unique_event_structs)}\")\n",
    "\n",
    "    struct2int = dict(zip(unique_event_structs, list(range(0, len(unique_event_structs)))))\n",
    "    int2struct = {i: e for e, i in struct2int.items()}\n",
    "\n",
    "    with open(dictionary_path, 'wb') as handle:\n",
    "        pickle.dump([struct2int, int2struct], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return event_structs, struct2int, int2struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98943aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ADL_MOZART\"\n",
    "training_set_path = f\"{checkpoint_path}/data/training_set_{dataset_name}.pkl\"\n",
    "dictionary_path = f\"{checkpoint_path}/dictionary/dictionary_{dataset_name}.pkl\"\n",
    "\n",
    "midi_paths = get_all_files(dataset_name=dataset_name)\n",
    "\n",
    "# Build lookup dictionaries\n",
    "#event_structs, struct2int, int2struct = build_lookups(midi_paths=midi_paths, training_set_path=training_set_path, dictionary_path=dictionary_path)\n",
    "\n",
    "# Load existing dictionaries\n",
    "event_structs = pickle.load(open(training_set_path, 'rb'))\n",
    "struct2int, int2struct = pickle.load(open(dictionary_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41cbf165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1557, 32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build training sequences of length 8\n",
    "# Define a list of targets which is the event struture that follows the training sequence\n",
    "sequenceLength = 32\n",
    "\n",
    "train_structs = []\n",
    "target_structs = []\n",
    "for i in range(len(event_structs)):\n",
    "    struct_list = [struct2int[s] for s in event_structs[i]]\n",
    "    for i in range(len(struct_list) - sequenceLength):\n",
    "        train_structs.append(struct_list[i:i+sequenceLength])\n",
    "        target_structs.append(struct_list[i+1])\n",
    "\n",
    "train_structs = np.asarray(train_structs, dtype=np.int64)\n",
    "target_structs = np.asarray(target_structs, dtype=np.int64)\n",
    "\n",
    "train_structs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c4f3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_structs, target_structs, output_size, output_file):\n",
    "    # Define input layers\n",
    "    struct_input = tf.keras.layers.Input(shape = (1, train_structs.shape[1]))\n",
    "\n",
    "    # Define LSTM layer\n",
    "    lstm_layer = tf.keras.layers.LSTM(512, return_sequences=True)(struct_input)\n",
    "\n",
    "    # Define dense layer\n",
    "    dense_layer = tf.keras.layers.Dense(256)(lstm_layer)\n",
    "\n",
    "    # Define output layers\n",
    "    struct_output = tf.keras.layers.Dense(output_size, activation = 'softmax')(dense_layer)\n",
    "\n",
    "    # Define model\n",
    "    lstm = tf.keras.Model(inputs = struct_input, outputs = struct_output)\n",
    "\n",
    "    # Compile the model\n",
    "    lstm.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Define data\n",
    "    training_x = train_structs.reshape((train_structs.shape[0], 1, train_structs.shape[1]))\n",
    "    training_y = target_structs\n",
    "\n",
    "    # Train the model\n",
    "    lstm.fit(training_x, training_y, epochs=100, batch_size=64)\n",
    "\n",
    "    # Save the model to file\n",
    "    lstm.save(output_file)\n",
    "\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dd2ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = f\"{checkpoint_path}/model/lstm_{dataset_name}_s{sequenceLength}.h5\"\n",
    "\n",
    "# Train the model\n",
    "#lstm = train_model(train_structs=train_structs, target_structs=target_structs, output_size=len(struct2int.keys()), output_file=model_file)\n",
    "\n",
    "# Load the model\n",
    "lstm = load_model(model_file, custom_objects={'Functional':tf.keras.models.Model}, compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9cd7967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 32)]           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1, 512)            1116160   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 256)            131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 2936)           754552    \n",
      "=================================================================\n",
      "Total params: 2,002,040\n",
      "Trainable params: 2,002,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2d6c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_structs(train_structs, rnd_idx, is_rand=False):\n",
    "    if is_rand:\n",
    "        initial_structs = []\n",
    "        for _ in range(train_structs.shape[1]):\n",
    "            initial_structs.append(np.random.randint(0, len(struct2int.values())))\n",
    "    else:\n",
    "        initial_structs = train_structs[rnd_idx,:].copy()\n",
    "\n",
    "    initial_structs = np.expand_dims(initial_structs, 0)\n",
    "    return initial_structs.reshape(1, initial_structs.shape[0], initial_structs.shape[1])\n",
    "\n",
    "def predictChords(struct_sequence):\n",
    "    predicted_structs= lstm.predict(struct_sequence)\n",
    "    return np.argmax(predicted_structs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9ecf5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(is_rand=False):\n",
    "    rnd_idx = np.random.randint(0, train_structs.shape[0])\n",
    "    print(f\"Index: {rnd_idx}\")\n",
    "\n",
    "    initial_structs = init_structs(train_structs, rnd_idx, is_rand)\n",
    "    # Define empty lists for event structures\n",
    "    new_structs_list = []\n",
    "\n",
    "    # Generate event structures \n",
    "    for j in range(20):\n",
    "        new_struct = predictChords(initial_structs)\n",
    "        new_structs_list.append(new_struct)\n",
    "        initial_structs[0][0][:-1] = initial_structs[0][0][1:]\n",
    "        initial_structs[0][0][-1] = new_struct\n",
    "\n",
    "    new_structs = [int2struct[s] for s in new_structs_list]\n",
    "    new_events = np.asarray(sum(new_structs,()), dtype=object)\n",
    "\n",
    "    output_path = f\"{checkpoint_path}/outputs/sample_{dataset_name}_s{sequenceLength}_{rnd_idx}.mid\"\n",
    "    events_to_midi(new_events, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b16e33a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 1066\n",
      "/Users/alecyu/Desktop/Repos/AppliedDeepLearning/note-zart/models/resource/gen2/v1/outputs/sample_ADL_MOZART_s32_1066.mid\n"
     ]
    }
   ],
   "source": [
    "generate(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
